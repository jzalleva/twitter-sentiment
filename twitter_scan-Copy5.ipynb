{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREVIOUS VERSION WILL ACQUIRE TWEETS AND PUT THEM IN SQL DATABASE TWEETS\n",
    "# PREVIOUS VERSION WILL ACQUIRE OLD TWEETS THAT HAVE BEEN RETWEETED\n",
    "# THIS VERSION WILL NOT COMMITT ANY RETWEETS OLDER THAN 7 Days\n",
    "# THIS VERSION WILL BREAK UP TWEETS INTO AN EQUAL NUMBER OF REQUESTS FOR EACH DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter apikey - VnEUFK7HUgAwcSa4yNbATnGrc\n",
    "#Twitter api secretkey - Tl0ywm860EWFSIC3dM4HrZ8Fw92kTrsFJOylUmfTdEatYAZm0k\n",
    "#Twitter bearer token - AAAAAAAAAAAAAAAAAAAAAJt4HAEAAAAA%2BuMkCsqy%2FE3mXODKjKItDO%2B8IoY%3Ds1FYI4Q0I23yWyMoiVPPUNctfZDpNljdAA8P5HcI37vq2tqhyW\n",
    "#On 01/12/2021 your consumer keys will no longer be visible.\n",
    "\n",
    "consumer_key = \"VnEUFK7HUgAwcSa4yNbATnGrc\"\n",
    "consumer_secret = \"Tl0ywm860EWFSIC3dM4HrZ8Fw92kTrsFJOylUmfTdEatYAZm0k\"\n",
    "token = \"AAAAAAAAAAAAAAAAAAAAAJt4HAEAAAAA%2BuMkCsqy%2FE3mXODKjKItDO%2B8IoY%3Ds1FYI4Q0I23yWyMoiVPPUNctfZDpNljdAA8P5HcI37vq2tqhyW\"\n",
    "\n",
    "access_token = '1298664925217210370-wRovRCyte8JShjsjg3k2MtBmMMe9na'\n",
    "access_token_secret = 'd8Ibm3dVSRMgXPkGCaEA7QbBf8IuY8cWGUdI65Au3I5g6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tweepy\n",
    "#pip install textblob\n",
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json\n",
    "import sqlite3\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from datetime import datetime as dt, timedelta\n",
    "\n",
    "#access to API\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret) \n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below functions are meant to be combined in one main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accesses Twitter based on user inputed search criteria - returns dictionary with 2 items \n",
    "# 1: List of 7 search results \n",
    "# 2: Search term\n",
    "\n",
    "def get_tweets():\n",
    "    #inputs for what you want to search and how many results to get\n",
    "    search_words = input(\"Input Search Here:\")\n",
    "    \n",
    "    num_results = input(\"Sets of 100 Tweets Desired (Press enter for maximum):\")\n",
    "    if num_results == '':\n",
    "        num_results = 180 #maximum pages for rate limit\n",
    "    elif int(num_results) < 7:\n",
    "        num_results = 7 #has to be at least 7 - one request per day\n",
    "    else:\n",
    "        num_results = int(num_results)\n",
    "    num_results = round(num_results/7) #requests per date\n",
    "    \n",
    "    date_list = []\n",
    "    current_date = dt.utcnow() \n",
    "    #Gives list of dates in format for the API\n",
    "    for i in range(7):\n",
    "        new_date = (current_date - timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
    "        date_list.append(new_date)\n",
    "        \n",
    "    tweets = []\n",
    "    for date in date_list:\n",
    "        day_tweets = tw.Cursor(api.search, q = search_words, lang = \"en\", result_type = 'mixed', count = 100 ,until = date, tweet_mode = 'extended').pages(num_results)\n",
    "        tweets.append(day_tweets)\n",
    "        \n",
    "    return {'tweets':tweets, 'search_words':search_words}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes retrieved tweets and creates smaller list\n",
    "def create_tweet_list(tweepy_cursor):\n",
    "    #Create a list with only the items we want from the tweet - decrease storage\n",
    "    #Dict keys - #['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'metadata', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang']\n",
    "    #add any of above keys if data is useful\n",
    "    desired_keys = ['created_at', 'id', 'full_text', 'entities'\n",
    "                    , 'metadata', 'in_reply_to_status_id'\n",
    "                    ,'in_reply_to_user_id', 'user', 'place', 'retweeted_status'\n",
    "                    , 'retweet_count', 'favorite_count', 'retweeted']\n",
    "    tweet_list = []\n",
    "    for page in tweepy_cursor:\n",
    "        for status in page:\n",
    "            status = status._json #gets the dictionary object only\n",
    "            newdict = {} \n",
    "            for key in desired_keys: #iterate through list of the keys we want\n",
    "                try:\n",
    "                    newdict.update({ key : status[key] }) #adds new key:value pair to dictionary item for a status\n",
    "                except KeyError: #loop back to key loop if there isn't a key present - used when there isnt a retweeted_status key\n",
    "                    continue\n",
    "            tweet_list.append(newdict)\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_tweets():\n",
    "    pull_tweets = get_tweets() \n",
    "    search_results = pull_tweets['tweets'] #this returns the list of 7 daily search results\n",
    "    result_list = []\n",
    "    #creates a list of lists with 7 elements\n",
    "    for daily_search_results in search_results:\n",
    "        new_results = create_tweet_list(daily_search_results) #this applies a function to refine that full list of tweets\n",
    "        result_list.append(new_results)\n",
    "    #flatten the list\n",
    "    big_list = []\n",
    "    for sublist in result_list:\n",
    "        for item in sublist:\n",
    "            big_list.append(item)\n",
    "    search_words = pull_tweets['search_words'] #returns the search term used to acquire the tweets\n",
    "    return {'tweets':big_list, 'search_words':search_words}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes the list of tweets returned from the api search and adds them to the SQL \"Tweets2\" database\n",
    "\n",
    "def add_to_DB():\n",
    "    tweet_data = compile_tweets() #calls function to get list of tweets and the search term used\n",
    "    list_of_tweets = tweet_data['tweets']\n",
    "    search_words = tweet_data['search_words']\n",
    "    conn = sqlite3.connect('tweets2.sqlite')\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    #Delete table if needed - only for when I'm testing stuff\n",
    "    cur.execute('''DROP TABLE IF EXISTS Tweets2''')\n",
    "\n",
    "    #Create the table and define data parameters\n",
    "    #Tweet ID is the primary key because we are interested in specific tweets\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS Tweets2\n",
    "                    (tweet_id INTEGER PRIMARY KEY UNIQUE\n",
    "                    , user_id INTEGER\n",
    "                    , user_name TEXT, name TEXT\n",
    "                    , text TEXT , time_posted INTEGER\n",
    "                    , retweet_count INTEGER, favorite_count INTEGER\n",
    "                    , place_id TEXT, place_name TEXT, place_coord TEXT\n",
    "                    , search_words TEXT, sentiment REAL, subjectivity REAL, clean_text TEXT, clean_time INTEGER)''')\n",
    "\n",
    "\n",
    "    #Create values to input into SQL table\n",
    "    error_tweets = [] #list of dictionaries to hold all items where errors occur\n",
    "    count = 0\n",
    "    for tweet in list_of_tweets:\n",
    "        count += 1\n",
    "        #First - If status is a retweet, we want to ignore it\n",
    "        try:\n",
    "            tweet['retweeted_status']\n",
    "            continue #Want to restart loop if we run into a retweet\n",
    "        #If it is not a retweet, then will give KeyError, so use \n",
    "        except KeyError:\n",
    "            tweet_id = tweet['id']\n",
    "            user_id = tweet['user']['id']\n",
    "            user_name = tweet['user']['screen_name']\n",
    "            name = tweet['user']['name']\n",
    "            text = tweet['full_text']\n",
    "            time_posted = tweet['created_at']\n",
    "            retweets = tweet['retweet_count']\n",
    "            favorites = tweet['favorite_count']\n",
    "            try:\n",
    "                place_id = tweet['place']['id']\n",
    "            except:\n",
    "                place_id = None\n",
    "            try:\n",
    "                place_name = tweet['place']['full_name']\n",
    "            except:\n",
    "                place_name = None\n",
    "            try:\n",
    "                place_coord = tweet['place']['coordinates']\n",
    "            except:\n",
    "                place_coord = None\n",
    "        \n",
    "        #clean the text & re-format date to unix timestamp for sql\n",
    "        clean_text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", text).split()) \n",
    "        clean_time = dt.strptime(time_posted, '%a %b %d %H:%M:%S %z %Y').timestamp()\n",
    "\n",
    "        #check polarity\n",
    "        sentiment = TextBlob(clean_text).sentiment[0] # (-1) to 1 scale\n",
    "        subjectivity =  TextBlob(clean_text).sentiment[1] # 0-1 scale\n",
    "        \n",
    "        #Insert into SQL table - Tweets\n",
    "        try:\n",
    "            cur.execute('''INSERT OR IGNORE INTO Tweets2\n",
    "            (tweet_id, user_id, user_name, name, text, time_posted, retweet_count\n",
    "            , favorite_count, place_id, place_name, place_coord, search_words, sentiment, subjectivity, clean_text, clean_time) \n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
    "            (tweet_id, user_id, user_name, name, text, time_posted, retweets, favorites\n",
    "            , place_id, place_name, place_coord, search_words, sentiment, subjectivity, clean_text, clean_time) )\n",
    "\n",
    "        except: \n",
    "            print(\"error\", count)\n",
    "            error_dict = {\"tweet_id\":tweet_id, \"user_id\":user_id, \"user_name\":user_name, \"name\":name, \"text\":text, \"time_posted\":time_posted, \"retweet_count\":retweets, \"favorite_count\":favorites, \"place_id\":place_id, \"place_name\":place_name, \"place_coord\":place_coord}\n",
    "            error_tweets.append(error_dict)\n",
    "            pass\n",
    "\n",
    "        #commit every 100th OR when we have reach the end of the list of tweets\n",
    "        if ((count % 1000 == 0) or (count == len(list_of_tweets)-1)) and count > 0:\n",
    "            conn.commit()\n",
    "            print(\"Committed\", count)\n",
    "            #Notify that all have been committed\n",
    "            if count == len(list_of_tweets)-1:\n",
    "                cur.execute('''SELECT COUNT(tweet_id) FROM Tweets2''')\n",
    "                num_tweets = cur.fetchone()[0] #if I dont do 0 it returns a one item list\n",
    "                print('Finished - ', num_tweets, \"tweets added to database out of\", len(list_of_tweets), \"tweets\" )\n",
    "          \n",
    "    cur.close() #always close the connection   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_to_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives the sentiment for each day\n",
    "def graph_data():\n",
    "    conn = sqlite3.connect('tweets2.sqlite')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''SELECT SUM(sentiment * (CASE WHEN retweet_count > 0 THEN retweet_count ELSE 1 END))\n",
    "                        /(SUM(retweet_count) + COUNT(tweet_id)) AS Sentiment\n",
    "                    , time_posted as Date\n",
    "                    , COUNT(tweet_id) as Num_Tweets\n",
    "                FROM Tweets2 \n",
    "                GROUP BY STRFTIME('%d', datetime(clean_time, 'unixepoch'))''') \n",
    "                #get the average sentiment of tweets that have a sentiment rating calculated\n",
    "\n",
    "    q = cur.fetchall()\n",
    "\n",
    "    #Create a list of results for the graph\n",
    "    daily_data = []\n",
    "    for item in q:\n",
    "        daily_list = []\n",
    "        date = item[1][0:10]\n",
    "        sentiment = round(item[0], 2)\n",
    "        daily_list = [date, sentiment]\n",
    "        daily_data.append(daily_list)\n",
    "    \n",
    "    cur.close()\n",
    "    return daily_data\n",
    "\n",
    "#Gives tweets positively affecting sentiment the most each day\n",
    "def pos_influencers():\n",
    "    conn = sqlite3.connect('tweets2.sqlite')\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute('''SELECT MAX( sentiment * (1 + retweet_count) ), time_posted, retweet_count, sentiment, name, text\n",
    "                    FROM Tweets2\n",
    "                    GROUP BY strftime('%d', datetime(clean_time, 'unixepoch'))''')\n",
    "    \n",
    "    q2 = cur.fetchall()\n",
    "    \n",
    "    pos_influencers = []\n",
    "    for item in q2:\n",
    "        date = item[1][0:10]\n",
    "        retweets = item[2]\n",
    "        sentiment = round(item[3], 2)\n",
    "        name = item[4]\n",
    "        text = item[5]\n",
    "        new_list = [date, name, text, sentiment, retweets]\n",
    "        pos_influencers.append(new_list)  \n",
    "     \n",
    "    #Gives tweets negatively affecting sentiment the most each day\n",
    "\n",
    "    cur.close()\n",
    "    return pos_influencers\n",
    "    \n",
    "def neg_influencers():\n",
    "    conn = sqlite3.connect('tweets2.sqlite')\n",
    "    cur = conn.cursor()    \n",
    "    \n",
    "    cur.execute('''SELECT MIN( sentiment * (1 + retweet_count) ), time_posted, retweet_count, sentiment, name, text\n",
    "                FROM Tweets2\n",
    "                GROUP BY strftime('%d', datetime(clean_time, 'unixepoch'))''')    \n",
    "\n",
    "    q3 = cur.fetchall()\n",
    "    \n",
    "    neg_influencers = []\n",
    "    for item in q3:\n",
    "        date = item[1][0:10]\n",
    "        retweets = item[2]\n",
    "        sentiment = round(item[3], 2)\n",
    "        name = item[4]\n",
    "        text = item[5]\n",
    "        new_list = [date, name, text, sentiment, retweets]\n",
    "        neg_influencers.append(new_list) \n",
    "        \n",
    "    cur.close()\n",
    "    return neg_influencers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next is to simply graph the results and print a nice list of the top influencers\n",
    "def print_influencers():\n",
    "    pos = pos_influencers()\n",
    "    neg = neg_influencers()\n",
    "    print(\"Most Influential Positive Tweets:\", '\\n', '----------------------')\n",
    "    count = 1\n",
    "    for i in pos:\n",
    "        print(count, '.', i[0], '-', i[1], '-', i[2] )\n",
    "        print('Sentiment:', i[3], '-', 'Retweets:', i[4])\n",
    "        count += 1\n",
    "        print('\\n')\n",
    "    \n",
    "    print('----------------------')\n",
    "    \n",
    "    print(\"Most Influential Negative Tweets:\", '\\n', '----------------------')\n",
    "    count = 1\n",
    "    for i in neg:\n",
    "        print(count, '.', i[0], '-', i[1], '-', i[2] )\n",
    "        print('Sentiment:', i[3], '-', 'Retweets:', i[4])\n",
    "        count += 1\n",
    "        print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input Search Here: Tour de France\n",
      "Sets of 100 Tweets Desired (Press enter for maximum): 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committed 1392\n",
      "Finished -  611 tweets added to database out of 1393 tweets\n",
      "\n",
      "\n",
      "Most Influential Positive Tweets: \n",
      " ----------------------\n",
      "1 . Wed Sep 02 - ITV Cycling - Sam Bennett becomes the first Irish rider in more than three decades to lead a Tour de France classification! @Sammmy_Be 👏💚\n",
      "\n",
      "#TDF2020 https://t.co/5EAbtYXFlo\n",
      "Sentiment: 0.25 - Retweets: 115\n",
      "\n",
      "\n",
      "2 . Fri Sep 04 - Peter Sagan - What an amazing job today by all my @BORAhansgrohe teammates, from start to finish. It's a pity that a mechanical in the sprint didn't allow me to finish off this huge effort. This is part of cycling... @BORAhansgrohe  https://t.co/DfXGB35yfh\n",
      "Sentiment: 0.3 - Retweets: 242\n",
      "\n",
      "\n",
      "3 . Sat Sep 05 - #Wine Guru🍷 - #Wine #Food: Tour de France by the Glass 2020 Stage 9: Bicycles, Bottles, and Books Before we look ahead to Sunday’s stage, let’s revisit how Stage 8 turned out. It was a good day for the French, with Nans Peters of the AG2R racing... https://t.co/oRiTfIbuQV via @theswirlingderv https://t.co/oPSXYUu2my\n",
      "Sentiment: 0.35 - Retweets: 2\n",
      "\n",
      "\n",
      "4 . Sun Sep 06 - Peloton&Tales - Tour de France 1913\n",
      "\n",
      "Grand Tours of the Week on @peloton_tales \n",
      "Tour de France before the Great War \n",
      "Come back for more! \n",
      "#tourdefrance  #retrocycling #vintagecycling #tdf2020 #cyclingstories #cyclinglegends #cyclinghistory https://t.co/IyBhxpjKQh\n",
      "Sentiment: 0.45 - Retweets: 1\n",
      "\n",
      "\n",
      "5 . Mon Sep 07 - Pro Cycling Memories - Santiago Botero 🇨🇴 wins Stage 9 (ITT) of the 2002 Tour De France from Lanester to Lorient (52km) #TDF2020 https://t.co/tn8E7RB7ix\n",
      "Sentiment: 0.3 - Retweets: 4\n",
      "\n",
      "\n",
      "6 . Tue Sep 08 - RTÉ Sport - Breaking: Sam Bennett has become only the sixth Irishman to win a stage of the Tour de France following a sprint finish to a blisteringly fast 10th day of racing.\n",
      "\n",
      "https://t.co/DXVsrnlgNL\n",
      "Sentiment: 0.25 - Retweets: 246\n",
      "\n",
      "\n",
      "7 . Wed Sep 09 - Simon Pagenaud - Rumor is there might be a beautiful yellow car along the Tour de France route tomorrow when they ride through my hometown of Montmorillon... be sure to tune in! #TourdeFrance #racing https://t.co/QKM0DK90Eo\n",
      "Sentiment: 0.45 - Retweets: 62\n",
      "\n",
      "\n",
      "8 . Thu Sep 10 - Cycling Weekly - 'I thought it was bike trouble, but it was just the legs': Julian Alaphilippe proves mortal once more on Tour de France stage 12 #TDF2020 | https://t.co/bj9oPlpNzp\n",
      "Sentiment: 0.2 - Retweets: 6\n",
      "\n",
      "\n",
      "----------------------\n",
      "Most Influential Negative Tweets: \n",
      " ----------------------\n",
      "1 . Wed Sep 02 - Irish Times Sport - Sam Bennett takes over green jersey at Tour de France https://t.co/NFl78anwvu via @IrishTimesSport\n",
      "Sentiment: -0.2 - Retweets: 8\n",
      "\n",
      "\n",
      "2 . Fri Sep 04 - Katie O Grady - @kylegriffin1 All those shallow accolade s,can be rescinded, like Olympic Medals,or Tour de France ones..just sayin\n",
      "Sentiment: -0.33 - Retweets: 2\n",
      "\n",
      "\n",
      "3 . Sat Sep 05 - AFP_Sport - It's been 35 years since a French cyclist won the Tour de France. Thibaut Pinot doesn't see that wait ending this year.\n",
      "\n",
      "'I'm sorry for my team and for the fans because I have failed so many times. This might be a turning point in my career.'\n",
      "\n",
      "https://t.co/rpOwAT0hhL #TDF2020 https://t.co/LzsFKjptcp\n",
      "Sentiment: -0.12 - Retweets: 11\n",
      "\n",
      "\n",
      "4 . Sun Sep 06 - Bloomberg - The Tour de France's coronavirus-related rules mean that the prospect of a team, or indeed the whole peloton, cycling into Paris on Sept. 20 is anything but guaranteed https://t.co/xE5PECOAzs\n",
      "Sentiment: -0.04 - Retweets: 11\n",
      "\n",
      "\n",
      "5 . Mon Sep 07 - Win! Leadership Based Interviews-Sports Headlines - Tour de France: How teams are handling COVID-19 pandemic behind the scenes – https://t.co/ak6hlcE388 https://t.co/ZSDP5WzXVI #malliard https://t.co/NjLTg1XI5l\n",
      "Sentiment: -0.4 - Retweets: 3\n",
      "\n",
      "\n",
      "6 . Tue Sep 08 - Reuters - French PM tests negative for COVID after contact at Tour de France https://t.co/nwaM1HPwjl https://t.co/UfYdkMlMa1\n",
      "Sentiment: -0.15 - Retweets: 15\n",
      "\n",
      "\n",
      "7 . Wed Sep 09 - Bruce Davies - @SBS so no Tour de France highlights in the morning anymore? Just breathtakingly boring tennis on both channels 😫👎\n",
      "Sentiment: -1.0 - Retweets: 0\n",
      "\n",
      "\n",
      "8 . Thu Sep 10 - Ned Boulting - On the Tour de France route today, we will see once again from the air the ruined village of Oradour-sur-Glane, the site of the massacre of 642 villagers on 10 June 1944. It is a startling sight, and was recently defaced by vandals, who replaced the word \"martyrs\" with \"liars\". https://t.co/MaIkEbMm6O\n",
      "Sentiment: -0.25 - Retweets: 220\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_top_influencers():\n",
    "    add_to_DB()\n",
    "    print('\\n')\n",
    "    print_influencers()\n",
    "\n",
    "get_top_influencers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
